{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on solving the 1D Blood Flow equations using Physics Informed Neural Networks.\n",
    "\n",
    "## Paris Perdikaris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textbf{Introduction}$$\n",
    "\n",
    "\\begin{align}\n",
    "&\\text{Recent advances in clinical measurement and computational modeling techniques introduce new capabilities for}\\\\\n",
    "&\\text{monitoring the human cardiovascular system from different perspectives such as disease surveys, bio-medical}\\\\\n",
    "&\\text{image processing, computational mathematic, bio-physics, etc. These studies reveal the crucial role}\\\\\n",
    "&\\text{ played by blood flow, arterial wall mechanics and pressure wave propagation, and how their interplay }\\\\\n",
    "&\\text{directly characterizes the functionality of the cardiovascular system both in health and disease (e.g., hypertensive\n",
    "disorders.)}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{Understanding the inner workings of the cardiovascular system has been central to many studies involving clinical,}\\\\\n",
    "&\\text{interventional or computational approaches. Although the in-vivo collected measurements can be highly accurate, }\\\\\n",
    "&\\text{such interventional techniques are sometimes expensive and suffer from limitations that are not easy to address,}\\\\\n",
    "&\\text{ e.g., difficulties of placing probes in cerebral or uteroplacental arteries. These limitations motivate the use of}\\\\\n",
    "&\\text{ non-invasive measurement techniques such as bio-medical imaging, advances in which currently define the clinical standard of care.}\\\\\n",
    "&\\text{Although non-invasive clinical measurement techniques involving Doppler ultrasound or MRI devices can be helpful, }\\\\\n",
    "&\\text{critical variables such as the pressure cannot be directly measured by a non-invasive technique. Accurate  }\\\\\n",
    "&\\text{measurements are only accessible by inserting a catheter equipped with sensors inside the vessel of interest.}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{These difficulties of directly measuring quantities of interest like the pressure in an in-vivo and non-invasive}\\\\\n",
    "&\\text{manner have motivated the use of computer simulations and computational fluid dynamics models to predict them in-silico. }\\\\\n",
    "&\\text{Advances in algorithms and computing resources now allow us to perform detailed flow simulations in\n",
    "complex}\\\\\n",
    "&\\text{patient-specific arterial topologies using three-dimensional (3D) and/or one-dimensional (1D) formulations}\\\\\n",
    "&\\text{of the unsteady Navier-Stokes equations. Such tools have been successfully validated against}\\\\\n",
    "&\\text{both in-vitro experiments as well as in-vivo clinical data, and provide a valuable platform for parametric sen-}\\\\\n",
    "&\\text{sitivity studies. Despite their predictive power, computational models have still not made their way into clinical}\\\\\n",
    "&\\text{practice primarily due to their high computational cost and the tedious procedures needed for their practical deploy-}\\\\\n",
    "&\\text{ment, e.g., mesh generation, parameter calibration, etc. For instance, such models require the precise subscription}\\\\\n",
    "&\\text{of boundary conditions that effectively capture the downstream flow dynamics in small arteries and arterioles via the}\\\\\n",
    "&\\text{use of Windkessel or structured tree models. Inaccurate calibration of the parameters associated with}\\\\\n",
    "&\\text{these boundary conditions is often the cause of brittleness in the resulting predictions, thus limiting the translational}\\\\\n",
    "&\\text{impact of computational models to the clinical domain. To mitigate these drawbacks an one-dimensional reduced order}\\\\\n",
    "&\\text{Navier-Stokes model is used coupled with the Physics Informed Neural Networks.}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\textbf{The goal of this tutorial is to provide a step-by-step introduction to Physics Informed Neural Networks for solving}\\\\\n",
    "&\\textbf{the problem of pulse wave propagation for an idealized carotid artery bifurcation.}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{Pulse wave propagation in arterial networks can be effectively modeled using one-dimensional (1D) reduced order}\\\\\n",
    "&\\text{models. In order to achieve the order reduction, a series of assumptions need to be made. First, we }\\\\\n",
    "&\\text{assume that the local curvature is small enough such that the geometry can be described using a Cartesian coordinate}\\\\\n",
    "&\\text{x, as shown in figure 1. Moreover, the fluid is incompressible and Newtonian, since we are considering }\\\\\n",
    "&\\text{geometries consisting of large arteries, so the density and dynamic viscosity are constant. Lastly, the structural }\\\\\n",
    "&\\text{properties of the artery are preserved at a cross-section. Following we consider a reduced form of the incompressible}\\\\\n",
    "&\\text{Navier-Stokes equations. Conservation of mass and momentum can be expressed as a hyperbolic conservation law}\\\\\n",
    "&\\text{that describes the evolution of blood velocity and cross-sectional area. In order to close the system, a}\\\\\n",
    "&\\text{third equation accounting for the relation between the pressure and the area is used, which is derived by assuming}\\\\\n",
    "&\\text{a thin wall tube and using Laplace’s law. This reduced order model provides an accurate representation of the}\\\\\n",
    "&\\text{underlying transport processes and its effectiveness in correctly capturing pulse wave propagation phenomena has}\\\\\n",
    "&\\text{been validated against both in-vitro and in-vivo data.}\\\\\n",
    "&\\text{The system derived by the above analysis takes the form:}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "\\begin{split} \n",
    "       & \\frac{\\partial A}{\\partial t} + \\frac{\\partial A u }{\\partial x} = 0, \\\\\n",
    "    & \\frac{\\partial u }{\\partial t} + u \\frac{\\partial u}{\\partial x} + \\frac{1}{\\rho} \\frac{\\partial p }{\\partial x}= 0, \\\\\n",
    "    & p = p_{ext} + \\beta ( \\sqrt{A} - \\sqrt{A_0}),\n",
    "\\end{split}\n",
    "\\label{equ:systemOfEquations}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{In the Physics Informed Neural Networks framework, the solution of partial differential equations is parametrized by a neural network that  }\\\\\n",
    "&\\text{is trained to match the measurements of the system, while being constrained to approximately satisfy the underlying  physical laws. In our }\\\\\n",
    "&\\text{particular case, we define one neural network $f (x, t; θ_j )$ to represent the solution of the equation (1) for vessel # j in our arterial network.}\\\\\n",
    "&\\text{In correspondence to system above, the following residuals can be defined:}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{split} \n",
    "       & r_{A}(x,t) :=  \\frac{\\partial A}{\\partial t} + \\frac{\\partial A u }{\\partial x}, \\\\\n",
    "    & r_{u}(x,t) :=  \\frac{\\partial u }{\\partial t} + u \\frac{\\partial u}{\\partial x} + \\frac{1}{\\rho} \\frac{\\partial p }{\\partial x},\\\\\n",
    "    & r_{p}(x,t) :=  p - p_{ext} - \\beta ( \\sqrt{A} - \\sqrt{A_0}).\n",
    "\\end{split}\n",
    "\\label{equ:PINNS_residual}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{In the system of eqautions describing the pulse wave propagtion, the order of magnitude of the different physical }\\\\\n",
    "&\\text{quantities, velocity, cross-sectional area and pressure, have a significant relative difference, e.g., $P \\sim 10^6$ Pa, $A \\sim 10^{−5}$ m$^2$ and $u \\sim 1 $m/s, }\\\\\n",
    "&\\text{which casts great difficulty on the training of the neural network. A direct application of the methods proposed in cannot\n",
    "handle this issue.}\\\\\n",
    "&\\text{For overcoming this problem, we employ a non-dimensionalization and normalization technique with the purpose of }\\\\\n",
    "&\\text{scaling the input and the output of the neural networks in a proper scale (e.g.,$(\\hat{A}, \\hat{u},\\hat{p}, x^* , t^∗ ) \\in [0, 1]) $}\\\\\n",
    "&\\text{and normalizing the spatial and temporal coordinates to have zero mean and unit variance for training the neural networks}\\\\\n",
    "&\\text{more efficiently. For the purpose of non-dimensionalization we introduce \n",
    "the characteristic variables,}\\\\\n",
    "&\\text{which are commonly used in multi-scale physics in order to simplify the equations. For this problem  \n",
    "we need a }\\\\\n",
    "&\\text{characteristic length $L$ and a characteristic velocity $U$. We will choose the characteristic length to be the square }\\\\ \n",
    "&\\text{root of the mean of the equilibrium cross-sectional area of the network vessels. In order to choose the characteristic }\\\\\n",
    "&\\text{velocity we make use of the physiological condition that the wave speed in a vessel has to be one order of magnitude }\\\\\n",
    "&\\text{larger than the length, given that, in the normalized length case $c = 10$. Thus:}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L = \\sqrt{ \\frac{1}{N} \\sum_{j=1}^{D}= (A^j_0)}  ,\\quad\\quad\\quad U = 10,$$\n",
    "\\begin{align}\n",
    "\\text{where $j = 1, ... , D$. At this point we define the quantities:}\n",
    "\\end{align}\n",
    "\\begin{equation}\\label{equ:non_dimensionalization}\n",
    "    \\hat{u} = \\dfrac{u}{U},\\quad \\hat{A} = \\dfrac{A}{A^o},\\quad \\hat{p} = \\dfrac{p}{p_0},\\quad x_* = \\dfrac{x}{L},\\quad t_* = \\dfrac{t}{T},\n",
    "\\end{equation}\n",
    "\\begin{align}\n",
    "\\text{where $p_0 = \\rho U^2$, $T = \\dfrac{L}{U}$ and $A^o = L^2$}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# Define the non-dimensionalazing parameters\n",
    "\n",
    "# Define equilibrium cross-sectional area\n",
    "self.A_01 = 1.35676200E-05   \n",
    "self.A_02 = 1.81458400E-06   \n",
    "self.A_03 = 1.35676200E-05   \n",
    "\n",
    "# Define problem parameters\n",
    "self.rho = 1060.\n",
    "self.beta1 =  69673881.97\n",
    "self.beta2 = 541788704.42\n",
    "self.beta3 =  69549997.97\n",
    "\n",
    "# Define non-dimensionalizing parameters\n",
    "self.U = 1e+1\n",
    "\n",
    "self.L = np.sqrt(0.333*(self.A_01 + self.A_02 + self.A_03))\n",
    "self.T = self.L/self.U\n",
    "self.p0 = self.rho*self.U**2        \n",
    "\n",
    "self.A0 = self.L**2  \n",
    "\n",
    "# Perform input non-dimensionalization\n",
    "\n",
    "x_u1 = x_u1/self.L\n",
    "x_u2 = x_u2/self.L\n",
    "x_u3 = x_u3/self.L\n",
    "\n",
    "x_f1 = x_f1/self.L\n",
    "x_f2 = x_f2/self.L\n",
    "x_f3 = x_f3/self.L\n",
    "\n",
    "t_f  = t_f/self.T\n",
    "t_u  = t_u/self.T\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{Now, the input of the neural network has support $(x^∗ , t^∗ ) \\in [0, 1]$. It is shown that normalizing the input to have}\\\\\n",
    "&\\text{zero mean and unit variance makes the training of the neural network more efficient as it prevents gradient saturation}\\\\\n",
    "&\\text{and provides stable updates. In this step, we will apply this technique to x ∗ and t ∗ , in the vessel # j, and get:}\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\\label{equ:normalization}\n",
    "    \\hat{x}^j = \\frac{x_*^j - \\mu^j_{x_*}}{\\sigma^j_{x_*}},\\quad \\hat{t} = \\frac{t_* - \\mu_{t^*}}{\\sigma_{t_*}},\n",
    "\\end{equation}\n",
    "\\begin{align}\n",
    "&\\text{where $\\mu^j_{x_*}$, $\\mu_{t_*}$ the mean value and $\\sigma^j_{x_*}$, $\\sigma_{t_*}$ the standard deviation }\\\\\n",
    "&\\text{of the spatial and temporal coordinates for the vessel $\\# j$, respectively, and $\\hat{x}^j$, $\\hat{t}$ the scaled inputs.}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "# Normalize inputs\n",
    "\n",
    "self.Xmean1, self.Xstd1 = x_f1.mean(0), x_f1.std(0)\n",
    "self.Xmean2, self.Xstd2 = x_f2.mean(0), x_f2.std(0)\n",
    "self.Xmean3, self.Xstd3 = x_f3.mean(0), x_f3.std(0)\n",
    "\n",
    "self.Tmean, self.Tstd = t_f.mean(0), t_f.std(0)\n",
    "\n",
    "# Find jacobians for spatial and temporal coordinates\n",
    "\n",
    "self.jac_x1 = 1.0/self.Xstd1\n",
    "self.jac_x2 = 1.0/self.Xstd2\n",
    "self.jac_x3 = 1.0/self.Xstd3\n",
    "\n",
    "self.jac_t = 1.0/self.Tstd\n",
    "\n",
    "\n",
    "# Define the new normalized/non-dimensionalized inputs\n",
    "\n",
    "self.X_f1 = (x_f1 - self.Xmean1)/self.Xstd1\n",
    "self.X_u1 = (x_u1 - self.Xmean1)/self.Xstd1\n",
    "\n",
    "self.X_f2 = (x_f2 - self.Xmean2)/self.Xstd2\n",
    "self.X_u2 = (x_u2 - self.Xmean2)/self.Xstd2\n",
    "\n",
    "self.X_f3 = (x_f3 - self.Xmean3)/self.Xstd3\n",
    "self.X_u3 = (x_u3 - self.Xmean3)/self.Xstd3\n",
    "\n",
    "self.T_u = (t_u - self.Tmean)/self.Tstd\n",
    "self.T_f = (t_f - self.Tmean)/self.Tstd\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{Using the variables stated above, we derive the updated system of equations (take vessel $\\# j$ as example):}\\\\\n",
    "\\end{align}\n",
    "\\begin{equation}\n",
    "\\begin{split} \\label{equ:NormSystem}\n",
    "       & \\frac{1}{\\sigma_{t_*}}\\frac{\\partial \\hat{A}^j}{\\partial \\hat{t}} + \\frac{1}{\\sigma^j_{x_*}}\\hat{A}^j\\frac{\\partial \\hat{u}^j}{\\partial \\hat{x}^j} + \\frac{1}{\\sigma^j_{x_*}}\\hat{u}^j\\frac{\\partial \\hat{A}^j}{\\partial \\hat{x}^j} = 0, \\\\\n",
    "    & \\frac{1}{\\sigma_{t_*}}\\frac{\\partial \\hat{u}^j}{\\partial \\hat{t}} + \\frac{1}{\\sigma^j_{x_*}}\\hat{u}^j\\frac{\\partial \\hat{u}^j}{\\partial\\hat{x}^j} + \\frac{1}{\\sigma^j_{x_*}}\\frac{\\partial \\hat{p}^j}{\\partial \\hat{x}^j} = 0 ,\\\\\n",
    "    & \\hat{p}^j = \\frac{1}{p_0} (p_{ext} + \\beta ( \\sqrt{\\hat{A}^j A^o} - \\sqrt{A_0})), \\quad \\quad j = 1, \\dots, D.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{align}\n",
    "&\\text{In this non-dimensional and normalized form, all the variables and inputs are scaled to order $O(1)$. This is what}\\\\\n",
    "&\\text{effectively enables the training of our physics-informed neural networks in this complex setting. Likewise, at the pre-}\\\\\n",
    "&\\text{dicting stage, we first scale the inputs by the characteristic variables, i.e. x by L, then normalize them.}\\\\\n",
    "&\\text{ Finally, we revert the predicted quantities ( $\\hat{A}^j$ , $\\hat{u}^j$ , $\\hat{p}^j$ ) back to their original form ( $A^j$ , $u^j$ , $p^j$ )}\\\\\n",
    "&\\text{by multiplying with the characteristic variables i.e. $p = \\hat{p}p_0$  .}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "``` python\n",
    "\n",
    "#  At this point we define the functions that perform the Physics Informed Neural Network\n",
    "#  technique. \n",
    "\n",
    "#  CAUTION :: The output of the neural network is in non-dimensional form!!\n",
    "\n",
    "def pinn_vessel_1(self, x, t):\n",
    "\n",
    "    A, u, p = self.neural_net_vessel_1(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "    r_p  =  self.beta1*(tf.sqrt(A*self.A0) - tf.sqrt(self.A_01)) \n",
    "\n",
    "    p_x = tf.gradients(p, x)[0]*self.jac_x1\n",
    "\n",
    "    A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "    A_x = tf.gradients(A, x)[0]*self.jac_x1\n",
    "\n",
    "    u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "    u_x = tf.gradients(u, x)[0]*self.jac_x1\n",
    "\n",
    "    r_A = A_t + u*A_x + A*u_x \n",
    "    r_u = u_t + p_x + u*u_x \n",
    "\n",
    "    return r_A, r_u, r_p\n",
    "\n",
    "def pinn_vessel_2(self, x, t):\n",
    "\n",
    "    A, u, p = self.neural_net_vessel_2(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "    r_p  =  self.beta2*(tf.sqrt(A*self.A0) - tf.sqrt(self.A_02)) \n",
    "\n",
    "    p_x = tf.gradients(p, x)[0]*self.jac_x2\n",
    "\n",
    "    A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "    A_x = tf.gradients(A, x)[0]*self.jac_x2\n",
    "\n",
    "    u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "    u_x = tf.gradients(u, x)[0]*self.jac_x2\n",
    "\n",
    "    r_A = A_t + u*A_x + A*u_x \n",
    "    r_u = u_t + p_x + u*u_x \n",
    "\n",
    "    return r_A, r_u, r_p\n",
    "\n",
    "def pinn_vessel_3(self, x, t):\n",
    "\n",
    "    A, u, p = self.neural_net_vessel_3(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "    r_p  =  self.beta3*(tf.sqrt(A*self.A0) - tf.sqrt(self.A_03)) \n",
    "    \n",
    "    p_x = tf.gradients(p, x)[0]*self.jac_x3\n",
    "\n",
    "    A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "    A_x = tf.gradients(A, x)[0]*self.jac_x3\n",
    "\n",
    "    u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "    u_x = tf.gradients(u, x)[0]*self.jac_x3\n",
    "    \n",
    "    r_A = A_t + u*A_x + A*u_x \n",
    "    r_u = u_t + p_x + u*u_x \n",
    "\n",
    "    return r_A, r_u, r_p\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function: Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{This part of the loss function corresponds to fitting the clinical measurements obtained for some of the vessels}\\\\\n",
    "&\\text{in the network. this term encourages the output of the neural network A and u to match the measurements of area and velocity}\\\\\n",
    "&\\text{obtained by a clinical procedure (e.g., segmenting 2D cine images and Doppler ultrasound [1]). This part of the loss function}\\\\\n",
    "&\\text{has the form (take vessel # j as example):}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\mathcal{L}_{\\textrm{measurement}}^j = \\frac{1}{N_u^j} \\sum_{i=1}^{N_u^j} ( u^j (x_i, t_i) - u^j(x_i, t_i; \\theta^j))^2 + \\frac{1}{N_A^j}\\sum_{i=1}^{N_A^j} ( A^j (x_i, t_i) - A^j(x_i, t_i; \\theta^j))^2, \\quad \\quad j = 1, \\dots, D_M\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "&\\text{where $N_A^j$, $N_u^j$ represent the number of measurements for $A$ and $u$ in vessel $\\# j$ respectively.}\\\\\n",
    "&\\text{Also, $D_M$ denote total number of vessels in which we have measurements. In the above equation $u^j (x_i, t_i; \\theta^j) $ } \\\\\n",
    "&\\text{and $ A^j(x_i, t_i; \\theta^j)$ represent the outputs given the parameters of the neural network for vessel $\\# j$. }\\\\\n",
    "&\\text{Minimizing this term will encourage the neural networks to fit the available measurements.}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "# We define the measurement loss for each vessel based on the above definition.\n",
    "\n",
    "# CAUTION :: The input of the measurement function ( output of the neural networks ) is in  \n",
    "#            non-dimensional form, so we have to revert it back to original form inside the loss\n",
    "#            function to perform the subtraction and then revert the loss back to \n",
    "#            non-dimensional to be consistent. \n",
    "\n",
    "def compute_measurement_loss_vessel_1(self, A_u, u_u):\n",
    "    \n",
    "    loss_A = tf.reduce_mean(tf.square((self.A_u1 - A_u*self.A0)/self.A0))\n",
    "    loss_u = tf.reduce_mean(tf.square((self.u_u1 - u_u*self.U)/self.U))\n",
    "    \n",
    "    return loss_A, loss_u\n",
    "\n",
    "def compute_measurement_loss_vessel_2(self, A_u, u_u):\n",
    "    \n",
    "    loss_A = tf.reduce_mean(tf.square((self.A_u2 - A_u*self.A0)/self.A0))\n",
    "    loss_u = tf.reduce_mean(tf.square((self.u_u2 - u_u*self.U)/self.U))\n",
    "    \n",
    "    return loss_A, loss_u\n",
    "\n",
    "def compute_measurement_loss_vessel_3(self, A_u, u_u):\n",
    "    \n",
    "    loss_A = tf.reduce_mean(tf.square((self.A_u3 - A_u*self.A0)/self.A0))\n",
    "    loss_u = tf.reduce_mean(tf.square((self.u_u3 - u_u*self.U)/self.U))\n",
    "    \n",
    "    return loss_A, loss_u\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function: Residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{This part of the loss function corresponds to the collocation points. These are points that we randomly choose }\\\\\n",
    "&\\text{inside the arterial domains using a latin-hypercube sampling strategy. Over these collocation}\\\\\n",
    "&\\text{points, we impose the physical constraints by encouraging the right hand side of the system of residual}\\\\ \n",
    "&\\text{Equations to be equal to zero. The partial derivatives in the residual expression can be computed using automatic }\\\\\n",
    "&\\text{differentiation. This objective is imposed to encourage the neural networks to find a particular set of }\\\\\n",
    "&\\text{parameters that make their predictions consistent with the underlying differential equations, which Translates to having}\\\\\n",
    "&\\text{the minimum residual. By satisfying this condition together with matching the measurements at particular  points,}\\\\\n",
    "&\\text{we can obtain a model that is capable of inferring the solution at any spatial coordinate of the domain and any time.}\\\\\n",
    "&\\text{This collocation loss function takes the following form (take vessel $\\# j$ as example):}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\mathcal{L}_{\\textrm{residual}}^j = \\frac{1}{N_r^j} \\sum_{i=1}^{N_r^j} ( r_A^j(x_i, t_i ; \\theta^j))^2 + \\frac{1}{N_r^j} \\sum_{i=1}^{N_r^j} ( r_u^j(x_i, t_i ;\n",
    "    \\theta^j))^2 + \\frac{1}{N_r^j} \\sum_{i=1}^{N_r^j} ( r_p^j(x_i, t_i ; \\theta^j))^2, \\quad \\quad j = 1,\n",
    "    \\dots, D\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{where N r j represent the number of collocation points in vessel $\\# j$.Also, $D$ denote the total number of vessels}\\\\\n",
    "&\\text{in our arterial network. The terms $r_A^j (x_i , t_i ; θ^j )$, r_u^j (x_i , t_i ; θ^j ) and r_p^j (x_i , t_i ; θ^j ) represent the residual of area, }\\\\\n",
    "&\\text{velocity and pressure, respectively.}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "# We define the residual loss based on the above definition.\n",
    "\n",
    "# CAUTION :: In this case, the residual of the A, u equations is in dimensional form,\n",
    "#            but the pressure residual is not, so we have to make to revert it. \n",
    "\n",
    "def compute_residual_loss_vessel_1(self, r_A, r_u, r_p):\n",
    "    loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "    loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "    loss_rp = tf.reduce_mean(tf.square((self.p_f_pred1 - r_p*(1/self.p0))))\n",
    "\n",
    "    return  loss_rA, loss_ru, loss_rp\n",
    "\n",
    "def compute_residual_loss_vessel_2(self, r_A, r_u, r_p):\n",
    "    loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "    loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "    loss_rp = tf.reduce_mean(tf.square((self.p_f_pred2 - r_p*(1/self.p0))))\n",
    "\n",
    "    return  loss_rA, loss_ru, loss_rp\n",
    "\n",
    "def compute_residual_loss_vessel_3(self, r_A, r_u, r_p):\n",
    "    loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "    loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "    loss_rp = tf.reduce_mean(tf.square((self.p_f_pred3 - r_p*(1/self.p0))))\n",
    "\n",
    "    return  loss_rA, loss_ru, loss_rp\n",
    "\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function:  Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{One-dimensional models can be extended to treat splitting and merging arteries by imposing proper boundary conditions.}\\\\\n",
    "&\\text{In this case, one needs to provide boundary conditions for each artery at the interface points to ensure conservation. }\\\\\n",
    "&\\text{In conventional numerical methods (e.g., Discontinuous Galerkin method), the velocity u and the area A can be discontinuous}\\\\\n",
    "&\\text{at the interface points (e.g., bifurcations, junctions), so in order to find the values, a Riemann problem has to be solved.}\\\\\n",
    "&\\text{This is typically done by employing the characteristic variables of the hyperbolic system), accounting for a decoupled system}\\\\\n",
    "&\\text{of scalar equations, so that the travelling waves can reach the splitting points. The proposed method can work without using}\\\\\n",
    "&\\text{information on the characteristics, instead just imposing the momentum and mass conservation equations suffices.}\\\\\n",
    "&\\text{To illustrate our workflow, let us consider the  case where the artery #1 splits to #2 and #3. For each vessel j, }\\\\\n",
    "&\\text{the area, velocity, pressure and density are denoted as $ [A^j , u^j , p^j ]$, the spatial and temporal variables }\\\\\n",
    "&\\text{are denoted as $[x_i , t_i ]$.}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{In order to be consistent with the derivation above, we have to follow the same procedure for every condition}\\\\\n",
    "&\\text{we impose to the model. In this notion we derive the non-dimensional continuity conditions, by inserting the non-dimensionalizing }\\\\\n",
    "&\\text{quantities into the conservation laws. By doing so, we get:}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\\label{equ:NormContinuity}\n",
    "    &\\hat{A}_{1}\\hat{u}_{1} =  \\hat{A}_{2}\\hat{u}_{2} +  \\hat{A}_{3}\\hat{u}_{3},\\\\\n",
    "    &\\hat{p}_{1} + \\frac{1}{2} (\\hat{u}_{1})^2  = \\hat{p}_{2} + \\frac{1}{2} (\\hat{u}_{2})^2,\\label{equ:NormContinuityp12} \\\\\n",
    "    &\\hat{p}_{1} + \\frac{1}{2} (\\hat{u}_{1})^2  = \\hat{p}_{3} + \\frac{1}{2} (\\hat{u}_{3})^2.\\label{equ:NormContinuityp13}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{Which produces the interface loss function:}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \\begin{align}\n",
    "    \\mathcal{L}_{\\textrm{interface}}^k = &\\frac{1}{N_b^k} \\sum_{i=1}^{N_b^k} ( A_1^k (x_k, t_i; \\theta_1^k)u_1^k (x_k, t_i; \\theta_1^k) - A_2^k(x_k, t_i; \\theta_2^k)u_2^k(x_k, t_i; \\theta_2^k) - A_3^k(x_k, t_i; \\theta_3^k)u_3^k(x_k, t_i; \\theta_3^k))^2 + \\\\\n",
    "    &+ \\frac{1}{N_b^k} \\sum_{i=1}^{N_b^k} ( p_1^k( x_k, t_i;\\theta_1^k) + \\frac{1}{2} u_1^k(x_k, t_i ;\\theta_1^k)^2 - p_2^k( x_k, t_i;\\theta_2^k) - \\frac{1}{2} u_2^k(x_k, t_i ;\\theta_2^k)^2)^2+ \\\\\n",
    "    &+ \\frac{1}{N_b^k} \\sum_{i=1}^{N_b^k} ( p_1^k( x_k, t_i;\\theta_1^k) + \\frac{1}{2} u_1^k(x_k, t_i ;\\theta_1^k)^2 -p_3^k( x_k, t_i;\\theta_3^k) - \\frac{1}{2} u_3^k(x_k, t_i ;\\theta_3^k)^2 )^2 , \\quad \\quad k=1, \\dots, D_I\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{where the indices 1, 2, 3 in $\\mathcal{L}^k_b$ denote the father and daughter vessels, respectively, at each bifurcation. Also, $D_I$}\\\\\n",
    "&\\text{denotes the total number of bifurcation points in our arterial network. $N_b^k$ represent the number of collocati on points}\\\\\n",
    "&\\text{on the interface boundaries. So, in the above equation if we choose for example $p^1_1$ that means we calculate }\\\\\n",
    "&\\text{the pressure at the interface point with index k = 1 using the network corresponding to the father vessel this}\\\\\n",
    "&\\text{ would correspond to domain 1. For the interface, we feed the neural network the inputs $[x_k , t]$, where $x_k$ is the}\\\\\n",
    "&\\text{ coordinate of the interface point. Minimizing the interface loss encourages the neural network to satisfy the }\\\\\n",
    "&\\text{ conservation laws at the interface points.}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "#    We define the loss at the interfaces based on the non-dimensional form of the\n",
    "#    conservation laws as explained above. \n",
    "\n",
    "def compute_interface_loss(self):\n",
    "\n",
    "     A1, u1, p1 = self.net_u1(self.X1_fm,self.t_f_tf) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "     A2, u2, p2 = self.net_u2(self.X2_fm,self.t_f_tf) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "     A3, u3, p3 = self.net_u3(self.X3_fm,self.t_f_tf) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "\n",
    "     Q1 = A1*u1\n",
    "     Q2 = A2*u2\n",
    "     Q3 = A3*u3\n",
    "\n",
    "     loss_mass = tf.reduce_mean(tf.square((Q1 - Q2 - Q3)))\n",
    "\n",
    "     p_1 = p1 + (0.5*u1**2)\n",
    "     p_2 = p2 + (0.5*u2**2)\n",
    "     p_3 = p3 + (0.5*u3**2)\n",
    "\n",
    "     loss_press = tf.reduce_mean(tf.square( p_1 - p_2)) + tf.reduce_mean(tf.square( p_1 - p_3))\n",
    "\n",
    "\n",
    "     return  loss_mass + loss_press \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python \n",
    "\n",
    "#  CAUTION :: It is very important to correctly define the coordinates of the \n",
    "#             interface points. To this point we have firstly followed a \n",
    "#             non-dimensionalization and then a normalization treatment of\n",
    "#             the spatial coordinates. Thus each interface point will be\n",
    "#             defined by an array whose elements is the non-dimensionalized\n",
    "#             and normalized spatial coordinate of the bifurcation point and \n",
    "#             size equal to the batch size ( N_batch = 1024). We define 3 arrays \n",
    "#             for the same point because we have 3 different jacobians and vessels.\n",
    "    \n",
    "X1_fm = bif_point/self.L\n",
    "X2_fm = bif_point/self.L\n",
    "X3_fm = bif_point/self.L\n",
    "\n",
    "bif_p1 = (X1_fm - self.Xmean1)/self.Xstd1\n",
    "bif_p2 = (X2_fm - self.Xmean2)/self.Xstd2\n",
    "bif_p3 = (X3_fm - self.Xmean3)/self.Xstd3\n",
    "\n",
    "X1max = bif_p1[0]\n",
    "X2min = bif_p2[0]\n",
    "X3min = bif_p3[0]\n",
    "\n",
    "# Initialize network weights and biases        \n",
    "self.weights1, self.biases1 = self.initialize_NN(layers)\n",
    "self.weights2, self.biases2 = self.initialize_NN(layers)\n",
    "self.weights3, self.biases3 = self.initialize_NN(layers)\n",
    "\n",
    "# Define placeholders and computational graph\n",
    "self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "\n",
    "self.X1_fm = tf.constant([X1max], shape = [1024,1], dtype=tf.float32)\n",
    "self.X2_fm = tf.constant([X2min], shape = [1024,1], dtype=tf.float32)\n",
    "self.X3_fm = tf.constant([X3min], shape = [1024,1], dtype=tf.float32)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Physics Informed Neural Networks for a real world carotid bifurcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](input_clinical_data.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "&\\text{ This example is about the use of this method in the case of a real carotid bifurcation. The input of the model is the}\\\\\n",
    "&\\text{velocity and cross-sectional area over time and the outputs are predictions of pressure over the whole domain }\\\\\n",
    "&\\text{( we do not provide information about the pressure) and the velocity and area at a testing point ( aorta3) in the}\\\\\n",
    "&\\text{figure above. This example is more involved than the previous discussed code as it contains 4 vessels having 2 bifurcations. }\\\\\n",
    "&\\text{Also, in this example the equilibrium cross-sectional area is not constant, but changes linearly in time.}\\\\\n",
    "&\\text{Thus, we define the $A_0$ and $\\beta$ as linear functions in the analysis. In this case we have to define two bifurcation}\\\\\n",
    "&\\text{points and treat them as described above.}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, X_measurement_aorta1, X_measurement_carotid,\\\n",
    "                       X_measurement_aorta3, X_measurement_aorta4,\n",
    "                       T_measurement, T_initial, \n",
    "                       A_training_aorta1,  U_training_aorta1,\n",
    "                          A_training_carotid, U_training_carotid,\n",
    "                          A_training_aorta3,  U_training_aorta3,\n",
    "                          A_training_aorta4,  U_training_aorta4, \n",
    "                          X_residual_aorta1, \n",
    "                          X_residual_carotid, \n",
    "                          X_residual_aorta3, \n",
    "                          X_residual_aorta4,\n",
    "                          T_residual,layers,bif_points):\n",
    "\n",
    "        self.A_01 = 2.293820e-04\n",
    "        self.A_02 = 2.623127e-05\n",
    "        self.A_03 = 2.411245e-04\n",
    "        \n",
    "        self.rho = 1060.                   \n",
    "        self.U = 1e+1\n",
    "\n",
    "        self.L = np.sqrt(0.333*(self.A_01 + self.A_02 + self.A_03))\n",
    "        self.T = self.L/self.U\n",
    "        self.p0 = self.rho*self.U**2        \n",
    "\n",
    "        self.A0 = self.L**2     \n",
    "        \n",
    "        X_measurement_aorta1 = X_measurement_aorta1/self.L\n",
    "        X_measurement_carotid = X_measurement_carotid/self.L\n",
    "        X_measurement_aorta3 = X_measurement_aorta3/self.L\n",
    "        X_measurement_aorta4 = X_measurement_aorta4/self.L\n",
    "        \n",
    "        X_residual_aorta1 = X_residual_aorta1/self.L\n",
    "        X_residual_carotid = X_residual_carotid/self.L\n",
    "        X_residual_aorta3 = X_residual_aorta3/self.L\n",
    "        X_residual_aorta4 = X_residual_aorta4/self.L\n",
    "        \n",
    "        T_measurement  = T_measurement/self.T\n",
    "        T_residual  = T_residual/self.T\n",
    "        T_initial  = T_initial/self.T\n",
    "        \n",
    "        # Normalize inputs\n",
    "        self.Xmean1, self.Xstd1 = X_residual_aorta1.mean(0), X_residual_aorta1.std(0)\n",
    "        self.Xmean2, self.Xstd2 = X_residual_carotid.mean(0), X_residual_carotid.std(0)\n",
    "        self.Xmean3, self.Xstd3 = X_residual_aorta3.mean(0), X_residual_aorta3.std(0)\n",
    "        self.Xmean4, self.Xstd4 = X_residual_aorta4.mean(0), X_residual_aorta4.std(0)\n",
    "\n",
    "        self.Tmean, self.Tstd = T_residual.mean(0), T_residual.std(0)\n",
    "        \n",
    "        self.jac_x1 = 1.0/self.Xstd1\n",
    "        self.jac_x2 = 1.0/self.Xstd2\n",
    "        self.jac_x3 = 1.0/self.Xstd3\n",
    "        self.jac_x4 = 1.0/self.Xstd4\n",
    "\n",
    "        self.jac_t = 1.0/self.Tstd\n",
    "        \n",
    "\n",
    "        self.X_f1 = (X_residual_aorta1 - self.Xmean1)/self.Xstd1\n",
    "        self.X_u1 = (X_measurement_aorta1 - self.Xmean1)/self.Xstd1\n",
    "        \n",
    "        self.X_f2 = (X_residual_carotid - self.Xmean2)/self.Xstd2\n",
    "        self.X_u2 = (X_measurement_carotid - self.Xmean2)/self.Xstd2\n",
    "        \n",
    "        self.X_f3 = (X_residual_aorta3 - self.Xmean3)/self.Xstd3\n",
    "        self.X_u3 = (X_measurement_aorta3 - self.Xmean3)/self.Xstd3\n",
    "\n",
    "        self.X_f4 = (X_residual_aorta4 - self.Xmean4)/self.Xstd4\n",
    "        self.X_u4 = (X_measurement_aorta4 - self.Xmean4)/self.Xstd4\n",
    "\n",
    "        self.T_u = (T_measurement - self.Tmean)/self.Tstd\n",
    "        self.T_f = (T_residual - self.Tmean)/self.Tstd\n",
    "        self.T_i = (T_initial - self.Tmean)/self.Tstd\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        self.A_u1 = A_training_aorta1 \n",
    "        self.u_u1 = U_training_aorta1\n",
    "        \n",
    "        self.A_u2 = A_training_carotid\n",
    "        self.u_u2 = U_training_carotid\n",
    "\n",
    "        self.A_u3 = A_training_aorta3 \n",
    "        self.u_u3 = U_training_aorta3\n",
    "\n",
    "        self.A_u4 = A_training_aorta4 \n",
    "        self.u_u4 = U_training_aorta4\n",
    "        \n",
    "        X1_fm = bif_points[0]/self.L\n",
    "        X2_fm = bif_points[0]/self.L\n",
    "        X3_fm1 = bif_points[0]/self.L\n",
    "        X3_fm2 = bif_points[1]/self.L\n",
    "        \n",
    "        \n",
    "        bif_p1 = (X1_fm - self.Xmean1)/self.Xstd1\n",
    "        bif_p2 = (X2_fm - self.Xmean2)/self.Xstd2\n",
    "        bif_p31 = (X3_fm1 - self.Xmean3)/self.Xstd3\n",
    "        bif_p32 = (X3_fm2 - self.Xmean3)/self.Xstd3\n",
    "        bif_p4 = (X3_fm2 - self.Xmean4)/self.Xstd4        \n",
    "       \n",
    "        X1max = bif_p1[0]\n",
    "        X2min = bif_p2[0]\n",
    "        X3min = bif_p31[0]\n",
    "        X3max = bif_p32[0]\n",
    "        X4min = bif_p4[0]\n",
    "\n",
    "        # Initialize network weights and biases        \n",
    "        self.weights1, self.biases1 = self.initialize_NN(layers)\n",
    "        self.weights2, self.biases2 = self.initialize_NN(layers)\n",
    "        self.weights3, self.biases3 = self.initialize_NN(layers)\n",
    "        self.weights4, self.biases4 = self.initialize_NN(layers)\n",
    "                       \n",
    "        # Define placeholders and computational graph\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        \n",
    "        self.X1_fm = tf.constant([X1max], shape = [1024,1], dtype=tf.float32)\n",
    "        self.X2_fm = tf.constant([X2min], shape = [1024,1], dtype=tf.float32)\n",
    "        self.X3_fml = tf.constant([X3min], shape = [1024,1], dtype=tf.float32)\n",
    "        self.X3_fmu = tf.constant([X3max], shape = [1024,1], dtype=tf.float32)\n",
    "        self.X4_fm = tf.constant([X4min], shape = [1024,1], dtype=tf.float32)\n",
    "        \n",
    "        self.A_u_tf1 = tf.placeholder(tf.float32, shape=(None, self.A_u1.shape[1]))\n",
    "        self.u_u_tf1 = tf.placeholder(tf.float32, shape=(None, self.u_u1.shape[1]))\n",
    "        \n",
    "        self.A_u_tf2 = tf.placeholder(tf.float32, shape=(None, self.A_u2.shape[1]))\n",
    "        self.u_u_tf2 = tf.placeholder(tf.float32, shape=(None, self.u_u2.shape[1]))\n",
    "\n",
    "        self.A_u_tf3 = tf.placeholder(tf.float32, shape=(None, self.A_u3.shape[1]))\n",
    "        self.u_u_tf3 = tf.placeholder(tf.float32, shape=(None, self.u_u3.shape[1]))\n",
    "\n",
    "        self.A_u_tf4 = tf.placeholder(tf.float32, shape=(None, self.A_u4.shape[1]))\n",
    "        self.u_u_tf4 = tf.placeholder(tf.float32, shape=(None, self.u_u4.shape[1]))\n",
    "                \n",
    "        self.X_u_tf1 = tf.placeholder(tf.float32, shape=(None, self.X_u1.shape[1]))\n",
    "        self.X_u_tf2 = tf.placeholder(tf.float32, shape=(None, self.X_u2.shape[1]))\n",
    "        self.X_u_tf3 = tf.placeholder(tf.float32, shape=(None, self.X_u3.shape[1]))\n",
    "        self.X_u_tf4 = tf.placeholder(tf.float32, shape=(None, self.X_u4.shape[1]))\n",
    "        \n",
    "        self.t_u_tf = tf.placeholder(tf.float32,  shape=(None, self.T_u.shape[1]))\n",
    "        self.t_i_tf = tf.placeholder(tf.float32,  shape=(None, self.T_i.shape[1]))\n",
    "\n",
    "        self.X_f_tf1 = tf.placeholder(tf.float32, shape=(None, self.X_f1.shape[1]))\n",
    "        self.X_f_tf2 = tf.placeholder(tf.float32, shape=(None, self.X_f2.shape[1]))\n",
    "        self.X_f_tf3 = tf.placeholder(tf.float32, shape=(None, self.X_f3.shape[1]))\n",
    "        self.X_f_tf4 = tf.placeholder(tf.float32, shape=(None, self.X_f4.shape[1]))\n",
    "\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=(None, self.T_f.shape[1]))\n",
    "        \n",
    "        self.A_u_pred1, self.u_u_pred1, _  = self.neural_net_aorta1(self.X_u_tf1, self.t_u_tf)\n",
    "        self.A_u_pred2, self.u_u_pred2, _  = self.neural_net_carotid(self.X_u_tf2, self.t_u_tf)\n",
    "        self.A_u_pred3, self.u_u_pred3, _  = self.neural_net_aorta3(self.X_u_tf3, self.t_i_tf)\n",
    "        self.A_u_pred4, self.u_u_pred4, _  = self.neural_net_aorta4(self.X_u_tf4, self.t_u_tf)\n",
    "        \n",
    "        self.A_f_pred1, self.u_f_pred1, self.p_f_pred1  = self.neural_net_aorta1(self.X_f_tf1, self.t_f_tf)\n",
    "        self.A_f_pred2, self.u_f_pred2, self.p_f_pred2  = self.neural_net_carotid(self.X_f_tf2, self.t_f_tf)\n",
    "        self.A_f_pred3, self.u_f_pred3, self.p_f_pred3  = self.neural_net_aorta3(self.X_f_tf3, self.t_f_tf)\n",
    "        self.A_f_pred4, self.u_f_pred4, self.p_f_pred4  = self.neural_net_aorta4(self.X_f_tf4, self.t_f_tf)\n",
    "        \n",
    "        self.r_A1, self.r_u1, self.r_p1  = self.pinn_aorta1(self.X_f_tf1, self.t_f_tf)\n",
    "        self.r_A2, self.r_u2, self.r_p2  = self.pinn_carotid(self.X_f_tf2, self.t_f_tf)\n",
    "        self.r_A3, self.r_u3, self.r_p3  = self.pinn_aorta3(self.X_f_tf3, self.t_f_tf)\n",
    "        self.r_A4, self.r_u4, self.r_p4  = self.pinn_aorta4(self.X_f_tf4, self.t_f_tf)\n",
    "               \n",
    "        self.loss_A1, self.loss_u1                 = self.compute_measurement_loss_aorta1(self.A_u_pred1, self.u_u_pred1)\n",
    "        self.loss_rA1, self.loss_ru1, self.loss_rp1 = self.compute_residual_loss_aorta1 (self.r_A1, self.r_u1, self.r_p1)\n",
    "        \n",
    "        self.loss_A2, self.loss_u2                 = self.compute_measurement_loss_carotid(self.A_u_pred2, self.u_u_pred2)\n",
    "        self.loss_rA2, self.loss_ru2, self.loss_rp2 = self.compute_residual_loss_carotid (self.r_A2, self.r_u2, self.r_p2)\n",
    "\n",
    "        self.loss_A3, self.loss_u3                 = self.compute_measurement_loss_aorta3(self.A_u_pred3, self.u_u_pred3)\n",
    "        self.loss_rA3, self.loss_ru3, self.loss_rp3 = self.compute_residual_loss_aorta3 (self.r_A3, self.r_u3, self.r_p3)\n",
    "\n",
    "        self.loss_A4, self.loss_u4                 = self.compute_measurement_loss_aorta4(self.A_u_pred4, self.u_u_pred4)\n",
    "        self.loss_rA4, self.loss_ru4, self.loss_rp4 = self.compute_residual_loss_aorta4 (self.r_A4, self.r_u4, self.r_p4)\n",
    "     \n",
    "        self.loss_interface  = self.compute_interface_loss()\n",
    "        \n",
    "        self.loss_A = self.loss_A1 + self.loss_A2 + self.loss_A3 + self.loss_A4\n",
    "        self.loss_u = self.loss_u1 + self.loss_u2 + self.loss_u3 + self.loss_u4\n",
    "        \n",
    "        self.loss_measurements = self.loss_A + self.loss_u\n",
    "        \n",
    "        self.loss_ru = self.loss_ru1 + self.loss_ru2 + self.loss_ru3 + self.loss_ru4\n",
    "        self.loss_rA = self.loss_rA1 + self.loss_rA2 + self.loss_rA3 + self.loss_rA4\n",
    "        self.loss_rp = self.loss_rp1 + self.loss_rp2 + self.loss_rp3 + self.loss_rp4\n",
    "        self.loss_residual = self.loss_rA + self.loss_ru + self.loss_rp\n",
    "        \n",
    "        self.loss = self.loss_interface + self.loss_residual  + self.loss_measurements\n",
    "        \n",
    "        # Define optimizer        \n",
    "        self.optimizer  = tf.train.AdamOptimizer(self.learning_rate)\n",
    "\n",
    "        self.train_op = self.optimizer.minimize(self.loss)\n",
    "        config = tf.ConfigProto(log_device_placement=True)\n",
    "        config.gpu_options.allow_growth = False\n",
    "        # Define Tensorflow session\n",
    "        self.sess = tf.Session(config=config)\n",
    "        \n",
    "        # Initialize Tensorflow variables\n",
    "        self.merged = tf.summary.merge_all()\n",
    "        \n",
    "        self.summary_writer = tf.summary.FileWriter('./logs', self.sess.graph)\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "   \n",
    "        self.sess.run(init)\n",
    "\n",
    "    \n",
    "    # Initialize network weights and biases using Xavier initialization\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "       \n",
    "           \n",
    "    def neural_net(self, H, weights, biases, layers):\n",
    "        num_layers = len(layers)  \n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def neural_net_aorta1(self, x, t):\n",
    "        Au = self.neural_net(tf.concat([x,t],1),self.weights1,self.biases1,self.layers)\n",
    "        A = Au[:,0:1]\n",
    "        u = Au[:,1:2]\n",
    "        p = Au[:,2:3]\n",
    "        return tf.exp(A), u, p\n",
    "    \n",
    "    def neural_net_carotid(self, x, t):\n",
    "        Au = self.neural_net(tf.concat([x,t],1),self.weights2,self.biases2,self.layers)\n",
    "        A = Au[:,0:1]\n",
    "        u = Au[:,1:2]\n",
    "        p = Au[:,2:3]\n",
    "        return tf.exp(A), u, p\n",
    "    \n",
    "    def neural_net_aorta3(self, x, t):\n",
    "        Au = self.neural_net(tf.concat([x,t],1),self.weights3,self.biases3,self.layers)\n",
    "        A = Au[:,0:1]\n",
    "        u = Au[:,1:2]\n",
    "        p = Au[:,2:3]\n",
    "        return tf.exp(A), u, p\n",
    "\n",
    "    def neural_net_aorta4(self, x, t):\n",
    "        Au = self.neural_net(tf.concat([x,t],1),self.weights4,self.biases4,self.layers)\n",
    "        A = Au[:,0:1]\n",
    "        u = Au[:,1:2]\n",
    "        p = Au[:,2:3]\n",
    "        return tf.exp(A), u, p\n",
    "   \n",
    "    def compute_interface_loss(self):\n",
    "        \n",
    "         A1, u1, p1 = self.neural_net_aorta1(self.X1_fm,self.t_f_tf) # A*, u*, p*\n",
    "         \n",
    "         A2, u2, p2 = self.neural_net_carotid(self.X2_fm,self.t_f_tf) # A*, u*, p*\n",
    "         \n",
    "         A3, u3, p3 = self.neural_net_aorta3(self.X3_fml,self.t_f_tf) # A*, u*, p*\n",
    "         \n",
    "         A3u, u3u, p3u = self.neural_net_aorta3(self.X3_fmu,self.t_f_tf) # A*, u*, p*\n",
    "\n",
    "         A4, u4, p4 = self.neural_net_aorta4(self.X4_fm,self.t_f_tf) # A*, u*, p*\n",
    "         \n",
    "         Q1 = A1*u1\n",
    "         Q2 = A2*u2\n",
    "         Q3 = A3*u3\n",
    "         \n",
    "         loss_mass = tf.reduce_mean(tf.square((Q1 - Q2 - Q3))) \n",
    "         \n",
    "         p_1 = p1 + (0.5*u1**2)\n",
    "         p_2 = p2 + (0.5*u2**2)\n",
    "         p_3 = p3 + (0.5*u3**2)\n",
    "         \n",
    "         loss_press = tf.reduce_mean(tf.square( p_1 - p_2)) + tf.reduce_mean(tf.square( p_1 - p_3))\n",
    "                                \n",
    "                         \n",
    "         loss_C = tf.reduce_mean(tf.square((u3u - u4))) + \\\n",
    "                             tf.reduce_mean(tf.square((A3u - A4))) + tf.reduce_mean(tf.square( p3u - p4))\n",
    "                             \n",
    "         return  loss_mass + loss_press + loss_C\n",
    "     \n",
    "\n",
    "    def get_equilibrium_cross_sectional_area_aorta_1(self, x):\n",
    "        x = self.L*(self.Xstd1*x + self.Xmean1)\n",
    "        X1 = 0.\n",
    "        X2 = 0.04964\n",
    "        denom = X2-X1\n",
    "        x1 = 2.293820e-04\n",
    "        x2 = 2.636589e-04\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "\n",
    "    def get_equilibrium_cross_sectional_area_carotid(self, x):\n",
    "        x = self.L*(self.Xstd2*x + self.Xmean2)\n",
    "        X1 = 0.04964\n",
    "        X2 = 0.10284\n",
    "        denom = X2-X1\n",
    "        x1 = 2.636589e-04\n",
    "        x2 = 2.623127e-05\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "\n",
    "    def get_equilibrium_cross_sectional_area_aorta_3(self, x):\n",
    "        x = self.L*(self.Xstd3*x + self.Xmean3)\n",
    "        X1 = 0.04964\n",
    "        X2 = 0.1383\n",
    "        denom = X2-X1\n",
    "        x1 = 2.636589e-04\n",
    "        x2 = 2.177177e-04\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "\n",
    "    def get_equilibrium_cross_sectional_area_aorta_4(self, x):\n",
    "        x = self.L*(self.Xstd4*x + self.Xmean4)\n",
    "        X1 = 0.1383\n",
    "        X2 = 0.17056\n",
    "        denom = X2-X1\n",
    "        x1 = 2.177177e-04\n",
    "        x2 = 2.411245e-04\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "\n",
    "    def get_beta_aorta_1(self, x):\n",
    "        x = self.L*(self.Xstd1*x + self.Xmean1)\n",
    "        X1 = 0.\n",
    "        X2 = 0.04964\n",
    "        denom = X2-X1\n",
    "        x1 = 2.472667e+06\n",
    "        x2 = 2.151208e+06\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "    \n",
    "    def get_beta_carotid(self, x):\n",
    "        x = self.L*(self.Xstd2*x + self.Xmean2)\n",
    "        X1 = 0.04964\n",
    "        X2 = 0.10284\n",
    "        denom = X2-X1\n",
    "        x1 =2.151208e+06\n",
    "        x2 = 9.459836e+06\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "    \n",
    "    def get_beta_aorta_3(self, x):\n",
    "        x = self.L*(self.Xstd3*x + self.Xmean3)\n",
    "        X1 = 0.04964\n",
    "        X2 = 0.1383\n",
    "        denom = X2-X1\n",
    "        x1 = 2.151208e+06\n",
    "        x2 = 2.800526e+06\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "    \n",
    "    def get_beta_aorta_4(self, x):\n",
    "        x = self.L*(self.Xstd4*x + self.Xmean4)\n",
    "        X1 = 0.1383\n",
    "        X2 = 0.17056\n",
    "        denom = X2-X1\n",
    "        x1 = 2.800526e+06\n",
    "        x2 = 2.528670e+06\n",
    "        numer =  x2 - x1 \n",
    "        alpha = numer/denom\n",
    "        beta = x1 - alpha*X1\n",
    "        y = alpha*x + beta\n",
    "        return y\n",
    "     \n",
    "    def pinn_aorta1(self, x, t):\n",
    "        \n",
    "        A, u, p = self.neural_net_aorta1(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "        \n",
    "        A_01 = self.get_equilibrium_cross_sectional_area_aorta_1(x)\n",
    "        beta1 = self.get_beta_aorta_1(x)\n",
    "        \n",
    "        r_p  = 10000. + beta1*(tf.sqrt(A*self.A0) - tf.sqrt(A_01)) \n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]*self.jac_x1\n",
    "\n",
    "        A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "        A_x = tf.gradients(A, x)[0]*self.jac_x1\n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "        u_x = tf.gradients(u, x)[0]*self.jac_x1\n",
    "                \n",
    "        r_A = A_t + u*A_x + A*u_x \n",
    "        r_u = u_t + p_x + u*u_x \n",
    "        \n",
    "        return r_A, r_u, r_p\n",
    "    \n",
    "    def pinn_carotid(self, x, t):\n",
    "        \n",
    "        A, u, p = self.neural_net_carotid(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "        \n",
    "        A_02 = self.get_equilibrium_cross_sectional_area_carotid(x)\n",
    "        beta2 = self.get_beta_carotid(x)\n",
    "        \n",
    "        r_p  = 8.5e+3 + beta2*(tf.sqrt(A*self.A0) - tf.sqrt(A_02)) \n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]*self.jac_x2\n",
    "\n",
    "        A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "        A_x = tf.gradients(A, x)[0]*self.jac_x2\n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "        u_x = tf.gradients(u, x)[0]*self.jac_x2\n",
    "                \n",
    "        r_A = A_t + u*A_x +  A*u_x \n",
    "        r_u = u_t + p_x + u*u_x \n",
    "        \n",
    "        return r_A, r_u, r_p\n",
    "    \n",
    "    def pinn_aorta3(self, x, t):\n",
    "        \n",
    "        A, u, p = self.neural_net_aorta3(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "        \n",
    "        A_03 = self.get_equilibrium_cross_sectional_area_aorta_3(x)\n",
    "        beta3 = self.get_beta_aorta_3(x)\n",
    "\n",
    "        r_p  = 10000. + beta3*(tf.sqrt(A*self.A0) - tf.sqrt(A_03)) \n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]*self.jac_x3\n",
    "\n",
    "        A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "        A_x = tf.gradients(A, x)[0]*self.jac_x3\n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "        u_x = tf.gradients(u, x)[0]*self.jac_x3\n",
    "                \n",
    "        r_A = A_t + u*A_x + A*u_x \n",
    "        r_u = u_t + p_x + u*u_x \n",
    "        \n",
    "        return r_A, r_u, r_p\n",
    "\n",
    "    def pinn_aorta4(self, x, t):\n",
    "        \n",
    "        A, u, p = self.neural_net_aorta4(x,t) # \\hat{A}, \\hat{u}, \\hat{p}\n",
    "        \n",
    "        A_04 = self.get_equilibrium_cross_sectional_area_aorta_4(x)\n",
    "        beta4 = self.get_beta_aorta_4(x)\n",
    "        \n",
    "        r_p  = 10000. + beta4*(tf.sqrt(A*self.A0) - tf.sqrt(A_04)) \n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]*self.jac_x4\n",
    "\n",
    "        A_t = tf.gradients(A, t)[0]*self.jac_t\n",
    "        A_x = tf.gradients(A, x)[0]*self.jac_x4\n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]*self.jac_t\n",
    "        u_x = tf.gradients(u, x)[0]*self.jac_x4\n",
    "                \n",
    "        r_A = A_t + u*A_x + A*u_x \n",
    "        r_u = u_t + p_x + u*u_x \n",
    "        \n",
    "        return r_A, r_u, r_p\n",
    "\n",
    "    def compute_residual_loss_aorta1(self, r_A, r_u, r_p):\n",
    "        loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "        loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "        loss_rp = tf.reduce_mean(tf.square((self.p_f_pred1 - r_p*(1/self.p0))))\n",
    "\n",
    "        return  loss_rA, loss_ru, loss_rp\n",
    "\n",
    "    def compute_residual_loss_carotid(self, r_A, r_u, r_p):\n",
    "        loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "        loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "        loss_rp = tf.reduce_mean(tf.square((self.p_f_pred2 - r_p*(1/self.p0))))\n",
    "\n",
    "        return  loss_rA, loss_ru, loss_rp\n",
    "\n",
    "    def compute_residual_loss_aorta3(self, r_A, r_u, r_p):\n",
    "        loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "        loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "        loss_rp = tf.reduce_mean(tf.square((self.p_f_pred3 - r_p*(1/self.p0))))\n",
    "\n",
    "        return  loss_rA, loss_ru, loss_rp \n",
    "\n",
    "    def compute_residual_loss_aorta4(self, r_A, r_u, r_p):\n",
    "        loss_rA = tf.reduce_mean(tf.square(r_A)) \n",
    "        loss_ru = tf.reduce_mean(tf.square(r_u))\n",
    "\n",
    "        loss_rp = tf.reduce_mean(tf.square((self.p_f_pred4 - r_p*(1/self.p0))))\n",
    "\n",
    "        return  loss_rA, loss_ru, loss_rp \n",
    "\n",
    "    def compute_measurement_loss_aorta1(self, A_u, u_u):\n",
    "    \n",
    "        loss_A = tf.reduce_mean(tf.square((self.A_u1 - A_u*self.A0)/self.A0))\n",
    "        loss_u = tf.reduce_mean(tf.square((self.u_u1 - u_u*self.U)/self.U))\n",
    "\n",
    "        return loss_A, loss_u\n",
    "\n",
    "    def compute_measurement_loss_carotid(self, A_u, u_u):\n",
    "\n",
    "        loss_A = tf.reduce_mean(tf.square((self.A_u2 - A_u*self.A0)/self.A0))\n",
    "        loss_u = tf.reduce_mean(tf.square((self.u_u2 - u_u*self.U)/self.U))\n",
    "\n",
    "        return loss_A, loss_u\n",
    "\n",
    "    def compute_measurement_loss_aorta3(self, A_u, u_u):\n",
    "\n",
    "        loss_A = tf.reduce_mean(tf.square((self.A_u3 - A_u*self.A0)/self.A0))\n",
    "        loss_u = tf.reduce_mean(tf.square((self.u_u3 - u_u*self.U)/self.U))\n",
    "\n",
    "        return loss_A, loss_u\n",
    "\n",
    "    def compute_measurement_loss_aorta4(self, A_u, u_u):\n",
    "\n",
    "        loss_A = tf.reduce_mean(tf.square((self.A_u4 - A_u*self.A0)/self.A0))\n",
    "        loss_u = tf.reduce_mean(tf.square((self.u_u4 - u_u*self.U)/self.U))\n",
    "\n",
    "        return loss_A, loss_u\n",
    "      \n",
    "    \n",
    "    def fetch_minibatch(self, X1_f, X2_f, X3_f ,X4_f, t_f, N_f_batch):        \n",
    "        N_f = X1_f.shape[0]\n",
    "        idx_f = np.random.choice(N_f, N_f_batch, replace=False)\n",
    "        X1_f_batch = X1_f[idx_f,:]\n",
    "        X2_f_batch = X2_f[idx_f,:]\n",
    "        X3_f_batch = X3_f[idx_f,:]\n",
    "        X4_f_batch = X4_f[idx_f,:]\n",
    "\n",
    "        t_f_batch = t_f[idx_f,:]        \n",
    "        return  X1_f_batch, X2_f_batch, X3_f_batch, X4_f_batch, t_f_batch\n",
    "             \n",
    "    # Trains the model by minimizing the MSE loss\n",
    "    def train(self, nIter = 20000, learning_rate = 1e-3): \n",
    "        \n",
    "    \n",
    "        start_time = timeit.default_timer()\n",
    "        \n",
    "        for it in range(nIter):\n",
    "            \n",
    "            X1_f_batch, X2_f_batch, X3_f_batch, X4_f_batch, T_f_batch = \\\n",
    "                    self.fetch_minibatch(self.X_f1, self.X_f2, self.X_f3, self.X_f4, self.T_f,\\\n",
    "                                         N_f_batch = 1024)\n",
    "            self.T_f_b = T_f_batch\n",
    "        # Define a dictionary for associating placeholders with data\n",
    "            tf_dict = {self.X_u_tf1: self.X_u1,  \n",
    "                       self.X_u_tf2: self.X_u2, \n",
    "                       self.X_u_tf3: self.X_u3, \n",
    "                       self.X_u_tf4: self.X_u4, \n",
    "                       self.X_f_tf1: X1_f_batch,\n",
    "                       self.X_f_tf2: X2_f_batch, \n",
    "                       self.X_f_tf3: X3_f_batch,\n",
    "                       self.X_f_tf4: X4_f_batch,\n",
    "                       self.t_f_tf:  T_f_batch, \n",
    "                       self.t_u_tf:  self.T_u,\n",
    "                       self.t_i_tf:  self.T_i,\n",
    "                       self.A_u_tf1: self.A_u1, self.u_u_tf1: self.u_u1, \n",
    "                       self.A_u_tf2: self.A_u2, self.u_u_tf2: self.u_u2,\n",
    "                       self.A_u_tf3: self.A_u3, self.u_u_tf3: self.u_u3,\n",
    "                       self.A_u_tf4: self.A_u4, self.u_u_tf4: self.u_u4,\n",
    "                       self.learning_rate: learning_rate}\n",
    "\n",
    "                 \n",
    "            # Run the Tensorflow session to minimize the loss\n",
    "            self.sess.run(self.train_op, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 100 == 0:\n",
    "                elapsed = timeit.default_timer() - start_time\n",
    "                loss_value, loss_A, loss_u, loss_r, loss_rp, loss_c  = self.sess.run([self.loss, self.loss_A, \\\n",
    "                                                self.loss_u, self.loss_ru+self.loss_rA, self.loss_rp, self.loss_interface], tf_dict)\n",
    "                print('It: %d, Loss: %.3e, Loss_A: %.3e, Loss_u: %.3e, Loss_r: %.3e, Loss_p: %.3e\\\n",
    "                                           Loss_c: %.3e, Time: %.2f' % \n",
    "                      (it, loss_value, loss_A, loss_u, loss_r, loss_rp, loss_c, elapsed))\n",
    "                start_time = timeit.default_timer()\n",
    "                                \n",
    "    # Evaluates predictions at test points           \n",
    "    def predict_aorta1(self, X1, t): \n",
    "        X1 = X1/self.L\n",
    "        t  = t/self.T\n",
    "        X1 = (X1 - self.Xmean1)/self.Xstd1\n",
    "\n",
    "        t = (t - self.Tmean)/self.Tstd\n",
    "        tf_dict1 = {self.X_f_tf1: X1, self.t_f_tf: t}    \n",
    "       \n",
    "        A_star1 = self.sess.run(self.A_f_pred1, tf_dict1) \n",
    "        u_star1 = self.sess.run(self.u_f_pred1, tf_dict1) \n",
    "        p_star1 = self.sess.run(self.p_f_pred1, tf_dict1) \n",
    "                \n",
    "        A_star1 = A_star1*self.A0\n",
    "        u_star1 = u_star1*self.U\n",
    "        p_star1 = p_star1*self.p0\n",
    "              \n",
    "        return A_star1, u_star1, p_star1\n",
    "\n",
    "    def predict_carotid(self, X2, t):     \n",
    "        X2 = X2/self.L\n",
    "        t  = t/self.T\n",
    "\n",
    "        X2 = (X2 - self.Xmean2)/self.Xstd2\n",
    "\n",
    "        t = (t - self.Tmean)/self.Tstd        \n",
    "        tf_dict2 = {self.X_f_tf2: X2, self.t_f_tf: t}    \n",
    "       \n",
    "        A_star2 = self.sess.run(self.A_f_pred2, tf_dict2) \n",
    "        u_star2 = self.sess.run(self.u_f_pred2, tf_dict2) \n",
    "        p_star2 = self.sess.run(self.p_f_pred2, tf_dict2) \n",
    "                \n",
    "        A_star2 = A_star2*self.A0\n",
    "        u_star2 = u_star2*self.U\n",
    "        p_star2 = p_star2*self.p0\n",
    "              \n",
    "        return A_star2, u_star2, p_star2\n",
    "    \n",
    "    def predict_aorta3(self, X3, t):     \n",
    "        X3 = X3/self.L\n",
    "        t  = t/self.T\n",
    "\n",
    "        X3 = (X3 - self.Xmean3)/self.Xstd3\n",
    "        t = (t - self.Tmean)/self.Tstd\n",
    "        \n",
    "        tf_dict3 = {self.X_f_tf3: X3, self.t_f_tf: t}    \n",
    "       \n",
    "        A_star3 = self.sess.run(self.A_f_pred3, tf_dict3) \n",
    "        u_star3 = self.sess.run(self.u_f_pred3, tf_dict3) \n",
    "        p_star3 = self.sess.run(self.p_f_pred3, tf_dict3) \n",
    "                \n",
    "        A_star3 = A_star3*self.A0\n",
    "        u_star3 = u_star3*self.U0\n",
    "        p_star3 = p_star3*self.p0\n",
    "              \n",
    "        return A_star3, u_star3, p_star3\n",
    "    \n",
    "    def predict_aorta4(self, X4, t):     \n",
    "        X4 = X4/self.L\n",
    "        t  = t/self.T\n",
    "\n",
    "        X4 = (X4 - self.Xmean4)/self.Xstd4\n",
    "        t = (t - self.Tmean)/self.Tstd\n",
    "        \n",
    "        tf_dict4 = {self.X_f_tf4: X4, self.t_f_tf: t}    \n",
    "       \n",
    "        A_star4 = self.sess.run(self.A_f_pred4, tf_dict4) \n",
    "        u_star4 = self.sess.run(self.u_f_pred4, tf_dict4) \n",
    "        p_star4 = self.sess.run(self.p_f_pred4, tf_dict4) \n",
    "                \n",
    "        A_star4 = A_star4*self.A0\n",
    "        u_star4 = u_star4*self.U\n",
    "        p_star4 = p_star4*self.p0\n",
    "              \n",
    "        return A_star4, u_star4, p_star4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_save/model.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f2604b7324d6>\", line 177, in <module>\n    T_residual,layers,bif_points)\n  File \"<ipython-input-2-e2c1c50480ba>\", line 213, in __init__\n    self.saver = tf.train.Saver()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_100 not found in checkpoint\n\t [[{{node save_1/RestoreV2}}]]\n\t [[{{node save_1/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f2604b7324d6>\", line 177, in <module>\n    T_residual,layers,bif_points)\n  File \"<ipython-input-2-e2c1c50480ba>\", line 213, in __init__\n    self.saver = tf.train.Saver()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f2604b7324d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./model_save/model.ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mtest_point1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.04964\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_residual_aorta1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-f2604b7324d6>\", line 177, in <module>\n    T_residual,layers,bif_points)\n  File \"<ipython-input-2-e2c1c50480ba>\", line 213, in __init__\n    self.saver = tf.train.Saver()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/gkissas/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey Variable_100 not found in checkpoint\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n\t [[node save_1/RestoreV2 (defined at <ipython-input-2-e2c1c50480ba>:213) ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def get_equilibrium_cross_sectional_area_aorta_1(x):\n",
    "    X1 = 0.0\n",
    "    X2 = 0.04964\n",
    "    denom = X2-X1\n",
    "    x1 = 2.293820e-04\n",
    "    x2 = 2.636589e-04\n",
    "    numer =  x2 - x1 \n",
    "    alpha = numer/denom\n",
    "    beta = x1 - alpha*X1\n",
    "    y = alpha*x + beta\n",
    "    return y\n",
    "\n",
    "def get_equilibrium_cross_sectional_area_carotid(x):\n",
    "    X1 = 0.04964\n",
    "    X2 = 0.10284\n",
    "    denom = X2-X1\n",
    "    x1 = 2.636589e-04\n",
    "    x2 = 2.623127e-05\n",
    "    numer =  x2 - x1 \n",
    "    alpha = numer/denom\n",
    "    beta = x1 - alpha*X1\n",
    "    y = alpha*x + beta\n",
    "    return y\n",
    "\n",
    "def get_equilibrium_cross_sectional_area_aorta_3(x):\n",
    "    X1 = 0.04964\n",
    "    X2 = 0.1383\n",
    "    denom = X2-X1\n",
    "    x1 = 2.636589e-04\n",
    "    x2 = 2.177177e-04\n",
    "    numer =  x2 - x1 \n",
    "    alpha = numer/denom\n",
    "    beta = x1 - alpha*X1\n",
    "    y = alpha*x + beta\n",
    "    return y\n",
    "\n",
    "def get_equilibrium_cross_sectional_area_aorta_4(x):\n",
    "    X1 = 0.1383\n",
    "    X2 = 0.17056\n",
    "    denom = X2-X1\n",
    "    x1 = 2.177177e-04\n",
    "    x2 = 2.411245e-04\n",
    "    numer =  x2 - x1 \n",
    "    alpha = numer/denom\n",
    "    beta = x1 - alpha*X1\n",
    "    y = alpha*x + beta\n",
    "    return y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Define the number of spatio-temporal domain points to evaluate the residual\n",
    "    # of the system of equations.\n",
    "    \n",
    "    N_f =  2000\n",
    "    \n",
    "    aorta1_velocity = np.load(\"Aorta1_U.npy\").item()\n",
    "    aorta2_velocity = np.load(\"Aorta2_U.npy\").item()\n",
    "    aorta4_velocity = np.load(\"Aorta4_U.npy\").item()\n",
    "    carotid_velocity= np.load(\"LCommonCarotid_U.npy\").item()\n",
    "\n",
    "    aorta1_area = np.load(\"Aorta1_A.npy\").item()\n",
    "    aorta2_area = np.load(\"Aorta2_A.npy\").item()\n",
    "    aorta4_area = np.load(\"Aorta4_A.npy\").item()\n",
    "    carotid_area = np.load(\"LCommonCarotid_A.npy\").item()\n",
    "    \n",
    "    test_aorta3_velocity = np.load(\"Aorta3_U.npy\").item()\n",
    "    test_aorta3_area = np.load(\"Aorta3_A.npy\").item()\n",
    "    \n",
    "    t = aorta1_velocity['t']*1e-3\n",
    "    \n",
    "    velocity_measurements_aorta1 = aorta1_velocity[\"U\"]*1e-2\n",
    "    velocity_measurements_carotid = carotid_velocity[\"U\"]*1e-2\n",
    "    velocity_measurements_aorta4 = aorta4_velocity[\"U\"]*1e-2\n",
    "    \n",
    "    area_measurements_aorta1 = aorta1_area[\"A\"]*1e-6\n",
    "    area_measurements_carotid = carotid_area[\"A\"]*1e-6\n",
    "    area_measurements_aorta4 = aorta4_area[\"A\"]*1e-6\n",
    "\n",
    "    velocity_testpoint_aorta3 = test_aorta3_velocity[\"U\"]*1e-2\n",
    "    area_testpoint_aorta3 = test_aorta3_area[\"A\"]*1e-6\n",
    "    \n",
    "    u_test1 = aorta2_velocity['U']*1e-2\n",
    "    A_test1 = aorta2_area['A']*1e-6\n",
    "    \n",
    "    # Number of measurements\n",
    "    \n",
    "    N_u = t.shape[0]\n",
    "\n",
    "    layers = [2, 100, 100, 100, 100, 100, 100, 3]\n",
    "    \n",
    "    lower_bound_t = t.min(0)\n",
    "    upper_bound_t = t.max(0)\n",
    "    \n",
    "    lower_bound_vessel_1 = 0.0   \n",
    "    upper_bound_vessel_1 = 0.04964\n",
    "    \n",
    "    lower_bound_vessel_2 = 0.04964\n",
    "    upper_bound_vessel_2 = 0.10284\n",
    "    \n",
    "    lower_bound_vessel_3 = 0.04964\n",
    "    upper_bound_vessel_3 = 0.1383\n",
    "\n",
    "    lower_bound_vessel_4 = 0.1383\n",
    "    upper_bound_vessel_4 = 0.17056\n",
    "    \n",
    "    # Spatial/temporal coordinates for initial conditions\n",
    "    X_initial_aorta1 = np.linspace(lower_bound_vessel_1,upper_bound_vessel_1,N_u)[:,None]\n",
    "    X_initial_carotid = np.linspace(lower_bound_vessel_2,upper_bound_vessel_2,N_u)[:,None]\n",
    "    X_initial_aorta3 = np.linspace(lower_bound_vessel_3,upper_bound_vessel_3,N_u)[:,None]\n",
    "    X_initial_aorta4 = np.linspace(lower_bound_vessel_4,upper_bound_vessel_4,N_u)[:,None]\n",
    "    \n",
    "    T_initial  = lower_bound_t*np.ones((N_u))[:,None]\n",
    "    \n",
    "    # Spatial/temporal coordinates for boundary conditions\n",
    "    X_boundary_aorta1 = lower_bound_vessel_1*np.ones((N_u))[:,None]\n",
    "    X_boundary_carotid = upper_bound_vessel_2*np.ones((N_u))[:,None]\n",
    "    X_boundary_aorta3 = upper_bound_vessel_3*np.ones((N_u))[:,None]\n",
    "    X_boundary_aorta4 = upper_bound_vessel_4*np.ones((N_u))[:,None]\n",
    "\n",
    "    T_boundary = t\n",
    "    \n",
    "    # Measurement Spatial/temporal coordinates\n",
    "    X_measurement_aorta1 = np.vstack((X_initial_aorta1, X_boundary_aorta1))\n",
    "    X_measurement_carotid = np.vstack((X_initial_carotid, X_boundary_carotid))    \n",
    "    X_measurement_aorta3 = np.vstack((X_initial_aorta3))    \n",
    "    X_measurement_aorta4 = np.vstack((X_initial_aorta4, X_boundary_aorta4))    \n",
    "    \n",
    "    T_measurement = np.vstack((T_initial, T_boundary))\n",
    "\n",
    "    X_residual_aorta1 = lower_bound_vessel_1 + (upper_bound_vessel_1-lower_bound_vessel_1)*np.random.random((N_f))[:,None]\n",
    "    X_residual_carotid = lower_bound_vessel_2 + (upper_bound_vessel_2-lower_bound_vessel_2)*np.random.random((N_f))[:,None]\n",
    "    X_residual_aorta3 = lower_bound_vessel_3 + (upper_bound_vessel_3-lower_bound_vessel_3)*np.random.random((N_f))[:,None]\n",
    "    X_residual_aorta4 = lower_bound_vessel_4 + (upper_bound_vessel_4-lower_bound_vessel_4)*np.random.random((N_f))[:,None]\n",
    "    \n",
    "    T_residual = lower_bound_t + (upper_bound_t-lower_bound_t)*np.random.random((N_f))[:,None]\n",
    "        \n",
    "    A_initial_aorta1 = get_equilibrium_cross_sectional_area_aorta_1(X_initial_aorta1)\n",
    "    A_initial_carotid = get_equilibrium_cross_sectional_area_carotid(X_initial_carotid)\n",
    "    A_initial_aorta3 = get_equilibrium_cross_sectional_area_aorta_3(X_initial_aorta3)    \n",
    "    A_initial_aorta4 = get_equilibrium_cross_sectional_area_aorta_4(X_initial_aorta4)\n",
    "    \n",
    "    \n",
    "    U_initial_aorta1 = velocity_measurements_aorta1[0]*np.ones((N_u,1))\n",
    "    U_initial_aorta2 = velocity_measurements_carotid[0]*np.ones((N_u,1))\n",
    "    U_initial_aorta3 = velocity_testpoint_aorta3[0]*np.ones((N_u,1))\n",
    "    U_initial_aorta4 = velocity_measurements_aorta4[0]*np.ones((N_u,1))\n",
    "         \n",
    "    A_training_aorta1 = np.vstack((A_initial_aorta1,area_measurements_aorta1))\n",
    "    U_training_aorta1 = np.vstack((U_initial_aorta1,velocity_measurements_aorta1))\n",
    "\n",
    "    A_training_carotid = np.vstack((A_initial_carotid,area_measurements_carotid))\n",
    "    U_training_carotid = np.vstack((U_initial_aorta2,velocity_measurements_carotid))\n",
    "    \n",
    "    A_training_aorta3 = np.vstack((A_initial_aorta3))\n",
    "    U_training_aorta3 = np.vstack((U_initial_aorta3))\n",
    "\n",
    "    A_training_aorta4 = np.vstack((A_initial_aorta4,area_measurements_aorta4))\n",
    "    U_training_aorta4 = np.vstack((U_initial_aorta4,velocity_measurements_aorta4))\n",
    "    \n",
    "    bif_points = [upper_bound_vessel_1, upper_bound_vessel_3]\n",
    "    \n",
    "    model = PhysicsInformedNN(X_measurement_aorta1, X_measurement_carotid,\\\n",
    "                              X_measurement_aorta3, X_measurement_aorta4,\\\n",
    "                              T_measurement, T_initial, \n",
    "                              A_training_aorta1,  U_training_aorta1,\\\n",
    "                              A_training_carotid, U_training_carotid,\\\n",
    "                              A_training_aorta3,  U_training_aorta3,\\\n",
    "                              A_training_aorta4,  U_training_aorta4, \\\n",
    "                              X_residual_aorta1, \\\n",
    "                              X_residual_carotid, \\\n",
    "                              X_residual_aorta3, \\\n",
    "                              X_residual_aorta4,\\\n",
    "                              T_residual,layers,bif_points)\n",
    "    \n",
    "    model.train(70000,1e-3)\n",
    "    model.train(35000,1e-4)\n",
    "    \n",
    "    test_point1 = 0.04964*np.ones((X_residual_aorta1.shape[0],1))    \n",
    "    test_point3 = 0.1383*np.ones((t.shape[0],1))\n",
    "        \n",
    "    test_aorta1_lboundary = lower_bound_vessel_1*np.ones((t.shape[0],1))\n",
    "    test_carotid_lboundary = lower_bound_vessel_2*np.ones((t.shape[0],1))\n",
    "    test_aorta4_lboundary = lower_bound_vessel_4*np.ones((t.shape[0],1))\n",
    "    \n",
    "    A_predict_aorta1, u_predict_aorta1, p_predict_aorta1     = model.predict_aorta1(test_point1, T_residual)\n",
    "    A_predict_carotid, u_predict_carotid, p_predict_carotid    = model.predict_carotid(test_point1, T_residual)\n",
    "    A_predict_aorta3l, u_predict_aorta3l, p_predict_aorta3l  = model.predict_aorta3(test_point1, T_residual)\n",
    "    A_predict_aorta4, u_predict_aorta4, p_predict_aorta4  = model.predict_aorta4(test_point3, t)\n",
    "    \n",
    "    A_pred1b, u_pred1b, p_pred1b  = model.predict_aorta1(test_aorta1_lboundary, t)\n",
    "    A_pred2b, u_pred2b, p_pred2b  = model.predict_carotid(test_carotid_lboundary, t)\n",
    "    A_pred3b, u_pred3b, p_pred3b  = model.predict_aorta4(test_aorta4_lboundary, t)\n",
    "\n",
    "    fig1 = plt.figure(1,figsize=(10, 6), dpi=400, facecolor='w', frameon = False)\n",
    "    fig2 = plt.figure(2,figsize=(10, 6), dpi=400, facecolor='w', frameon = False)\n",
    "    fig3 = plt.figure(3,figsize=(10, 6), dpi=400, facecolor='w', frameon = False)\n",
    "   \n",
    "    fig1.clf()\n",
    "    fig2.clf()\n",
    "    fig3.clf()\n",
    "  \n",
    "    ax1 = fig1.add_subplot(111)  \n",
    "    ax2 = fig2.add_subplot(111)  \n",
    "    ax3 = fig3.add_subplot(111)  \n",
    "   \n",
    "    ax1.plot(t, u_predict_aorta4,'r--',linewidth=3.5, markersize=2.5)\n",
    "    ax1.plot(t, velocity_testpoint_aorta3,'b-',linewidth=3.5, markersize=2.5)\n",
    "\n",
    "    ax1.set_xlabel('Time in $s$')\n",
    "    ax1.set_ylabel('Velocity in $m/s$')\n",
    "    ax1.set_title('Compare velocity aorta3')\n",
    "    \n",
    "    ax2.plot(t, A_predict_aorta4,'r--',linewidth=3.5, markersize=2.5)\n",
    "    ax2.plot(t, area_testpoint_aorta3,'b-',linewidth=3.5, markersize=2.5)\n",
    "\n",
    "    ax2.set_xlabel('Time in $s$')\n",
    "    ax2.set_ylabel('Area in $mm^2$')\n",
    "    ax2.set_title('Compare area aorta3')\n",
    "    \n",
    "    ax3.plot(t, p_predict_aorta4/133.,'r--',linewidth=3.5, markersize=2.5)\n",
    "\n",
    "    ax3.set_xlabel('Time in $s$')\n",
    "    ax3.set_ylabel('Pressure in $mmHg$')\n",
    "    ax3.set_title('Pressure aorta3')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\textbf{Predicted pressure ($mmHg$) versus time ($s$) for aorta3 test point}\n",
    "\\end{align}\n",
    "![alt text](pressure.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\textbf{Comparison of predicted and measured Area ($mm^2$) versus time ($s$) for aorta3 test point}\n",
    "\\end{align}\n",
    "\n",
    "![alt text](comparative_area3.png \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\textbf{Comparison of predicted and measured Velocity ($m/s$) versus time ($s$) for aorta3 test point}\n",
    "\\end{align}\n",
    "\n",
    "![alt text](comparative_velocity3.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
